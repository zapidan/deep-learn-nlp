{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "DeepLearningModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdQ6Q5MkgJSf",
        "colab_type": "text"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPhhCPDxgJSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# data = pd.read_csv('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz', compression='gzip')\n",
        "df = pd.read_csv('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.tokenized.csv.gz', compression='gzip').sample(frac = 1, random_state = 8).reset_index(drop = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ndIgvIgJSl",
        "colab_type": "text"
      },
      "source": [
        "# Select Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDL7G_fagJSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = df[df.category.isin(['title'])].copy()\n",
        "corpus = corpus[(corpus.n_tokens > 10) & (corpus.n_tokens < 500)].reset_index(drop = True).copy()\n",
        "corpus.head()\n",
        "# Need to sample corpus or training takes forever\n",
        "red_corpus = corpus.sample(10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukrz-0AogJSt",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize Input Sequence (X) Using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VMTL5EdgcSQ",
        "colab_type": "code",
        "outputId": "944f87ea-4d2f-4324-995e-b653387ed2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Fix Tensorflow\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3IIhS-JgJSv",
        "colab_type": "code",
        "outputId": "477d49c5-bf10-402b-b06d-3f23e5971c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "texts = red_corpus.tokens\n",
        "\n",
        "# Update internal vocabulary based on a list of texts\n",
        "tokenizer.fit_on_texts(texts)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"vocabulary size: %d\" %vocab_size)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary size: 6829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC1Xtbzev9l1",
        "colab_type": "code",
        "outputId": "8be65d22-a274-4a91-dd4f-97fd63526ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_sequences = []\n",
        "for line in texts:\n",
        "    encoded_tokens = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded_tokens)):\n",
        "        n_gram_sequence = encoded_tokens[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "print('Total Sequences: %d' % len(input_sequences))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 122917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWA0UFn8gJSy",
        "colab_type": "text"
      },
      "source": [
        "# Build Fix Length Sequences of Token Indexes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k_5ISfsgJSz",
        "colab_type": "code",
        "outputId": "8a51d946-6e7c-4fb4-d78b-237ed6b93c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "print('Max Sequence Length: %d' % max_sequence_len)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Sequence Length: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ZpxWosgJS3",
        "colab_type": "text"
      },
      "source": [
        "# Split the Sequence Into Predictors and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1uW6pP6gJS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.utils as ku \n",
        "\n",
        "# create predictors and label (X(input) and y(output))\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "label = ku.to_categorical(label, num_classes=vocab_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O9T-bTsgJS8",
        "colab_type": "text"
      },
      "source": [
        "# Define a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HreUud79gJS9",
        "colab_type": "code",
        "outputId": "d189e8fa-e4d5-4197-a296-c38e50403bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "from tensorflow.python.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150, return_sequences = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x=predictors, y=label, batch_size=100, epochs=1, verbose=1, use_multiprocessing=True)\n",
        "print(model.summary())"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 122917 samples\n",
            "122917/122917 [==============================] - 177s 1ms/sample - loss: 6.6076 - accuracy: 0.0389\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 35, 10)            68290     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 35, 150)           96600     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 35, 150)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 100)               100400    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6829)              689729    \n",
            "=================================================================\n",
            "Total params: 955,019\n",
            "Trainable params: 955,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rg3wHKoLFPz",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_awhgGLElv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(seed_text, next_words, max_sequence_len, model):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict_classes(token_list, verbose=0)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KrwCUkjLLVX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "545f2c60-3367-48cf-d9ba-2e79c3f48fbf"
      },
      "source": [
        "texts.sample(10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24093    is it valid to use t - test when using ratio o...\n",
              "27883    proving that the estimators of coefficients an...\n",
              "16982    how does xgboost python differentiate between ...\n",
              "9605      limit of c . d . f . of poisson goes to infinity\n",
              "23540    r prop . test - chi - squared approximation ma...\n",
              "16381    expectation of a variable inside the cumulativ...\n",
              "9685     approach to scale the size of investment with ...\n",
              "23266    evaluating unbiased errors on the test set whe...\n",
              "20150    what would be an appropriate y axis when plott...\n",
              "18104    summarize multiple distributions into one , sp...\n",
              "Name: tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-ya0b0LLOKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_text(\"summarize multiple distributions\", 10, max_sequence_len, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRBM_d6pYQZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset_text = corpus.sample(10000).text.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}