{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv and inspect dataframe\n",
    "df = pd.read_csv('../datasets/input/stackexchange_812k.csv', index_col='post_id')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regex expresions\n",
    "nums = r'^\\d+'\n",
    "html = r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6})'\n",
    "punct = r'[.!?\\\\-\\\\/,]'\n",
    "latex = r'(\\$[^\\$]+(?=\\$[^\\$]*)\\$)'\n",
    "url = r'(https?:\\/\\/)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
    "\n",
    "\n",
    "textCol = df['text']\n",
    "numsDf = textCol.str.contains(nums)\n",
    "htmlDf = textCol.str.contains(html)\n",
    "urlDf = textCol.str.contains(url)\n",
    "punctDf = textCol.str.contains(punct)\n",
    "latexDf = textCol.str.contains(latex)\n",
    "\n",
    "# Replace known unwanted regex with whitespace\n",
    "df['text'] = np.where(numsDf, textCol.str.replace(nums, ''),\n",
    "                     np.where(latexDf, textCol.str.replace(latex, ''),\n",
    "                             np.where(htmlDf, textCol.str.replace(html, ''),\n",
    "                                      np.where(urlDf, textCol.str.replace(url, ''),\n",
    "                                               np.where(punctDf, textCol.str.replace(punct, ''), textCol)))))\n",
    "                                            \n",
    "### Alternative to remove whole rows\n",
    "# filtered_df = df[\n",
    "#     (df['text'].str.contains(words)) & (~(df['text'].str.contains(html)))\n",
    "#     &  (~(df['text'].str.contains(nums))) & (~(df['text'].str.contains(punct)))\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "import nltk\n",
    "df['tokenized_texts'] = df.apply(lambda row: nltk.tokenize.casual.casual_tokenize(row['text'], preserve_case = False), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "df.to_csv('../datasets/output/tokenized.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
